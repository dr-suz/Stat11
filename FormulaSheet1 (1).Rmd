---
title: "Formula Sheet"
subtitle: "STAT 011"
output: pdf_document
---


```{r setup_pres, include=FALSE, echo=FALSE}
rm(list=ls())
library('tidyverse')
library('gridExtra')

#setwd("~/Google Drive Swat/Swat docs/Stat 21/Data")
options(htmltools.dir.version = FALSE)
```


## For a sample of data

If $\{x_1,x_2,\dots,x_n\}$ is a data set of $n$ observational units, we have the following:

Sample mean 
$$\bar{x} = \frac{1}{n}\sum_{i=1}^{n}x_i$$ 

Sample variance 
$$s^2 =  \frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})^2$$ 

Sample standard deviation 
$$s = \sqrt{s^2}$$ 

If we want to standardize the data set $X$, to create a new standardized data set $Z = \{ z_1, z_2, \dots, z_n \}$ we preform
$$z_i = \frac{x_i-\bar{x}}{s}, \text{ for $i=1,\dots,n$}.$$  


## For a random variable 

If $X$ represents a random variable (a theoretical random observation from some population), and $S$ is the sample space of all possible values of $X$, the mean (expectation) of $X$ is 
\begin{align*}
\mu = E(X) &=  \sum_{x \in S}xP(X=x) \\
&= \text{sum of the possibilities of $X$ times their probabilities}
\end{align*}
and the variance of $X$ is 
\begin{align*}
\sigma^2= Var(X) &= \sum_{x \in S}(x-E(X))^2P(X=x) \\
&=\text{sum of the squared difference between the possibilities of $X$ and $E(X)$}\\ 
&\quad\quad \text{times the corresponding probabilities}
\end{align*} 
and the standard deviation is $\sigma=\sqrt{\sigma^2}$. 

\pagebreak 

## Properties of mean and variance 

Linear transformations: 

  - $E(aX+b) = aE(X) + b$
  - $Var(aX+b) = a^2Var(X)$ 

For two random variables (or random samples) $X$ and $Y$: 

  - $E(X\pm Y) = E(X) \pm E(Y)$
  - $Var(X \pm Y) = Var(X) + Var(Y) \pm 2 Cov(X,Y)$ 
  - $Cor(X,Y) = \frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}$


## Properties of probabilities:

Suppose $A$ is an arbitrary event and $S$ is the sample space of all possible events. Then 

  - $0 \leq P(A) \leq 1$ 
  - $P(S)=1$ 
  - $P(A) = 1 - P(A^C)$
  - $P(A \text{ or } B) = P(A) + P(B) - P(A \text{ and } B)$. 

Definition of independence: Events $A$ and $B$ are independent if $P(A \text{ and } B) = P(A)\times P(B)$ 

Definition of conditional probability: $P(A \mid B) = \frac{P(A \cap B)}{P(B)}.$

If random variables $X$ and $Y$ are independent, then $Cov(X,Y)=0$. 

## Sampling distribution of the sample proportion 

The Central Limit Theorem states that under some general conditions, 
$$\hat{p} \sim N\left(p, \frac{p(1-p)}{n} \right).$$

## Statistical inference for population proportions 

The formula for the test statistic (also called the z-score) for a hypothesis test about a population proportion is:
$$T.S. = \frac{\hat{p} - p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}}.$$

The formula for a confidence interval (CI) for a population proportion is: 
$$\hat{p} \pm \left( z^*_{\alpha/2} \times \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}\right).$$